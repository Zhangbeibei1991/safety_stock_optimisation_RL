{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eek31/Documents/openai/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actor-critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(state, action):\n",
    "    return np.array([state[0], state[1], action[0]])\n",
    "\n",
    "def Q_approx(state, action, w):\n",
    "    return phi(state, action) @ w\n",
    "\n",
    "def mu(state, θ):\n",
    "    return np.array([state @ θ])\n",
    "\n",
    "def policy_approx(mu_action, σ, env):\n",
    "    return np.clip(np.random.normal(mu_action, σ, size=(1,)), env.action_space.low[0], env.action_space.high[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 0.8\n",
    "α = 0.1\n",
    "β = 0.2\n",
    "θ = np.random.rand(2,)\n",
    "w = np.random.rand(3,)\n",
    "σ = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "render = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A/home/eek31/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in matmul\n",
      "  \"\"\"\n",
      "/home/eek31/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in matmul\n",
      "  \"\"\"\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-c2f339a1f49b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mσ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# get next action using trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmu_new_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mθ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/openai/gym/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/openai/gym/gym/envs/classic_control/continuous_mountain_car.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mreward\u001b[0m\u001b[0;34m-=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvelocity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: math range error"
     ]
    }
   ],
   "source": [
    "num_episodes = 200\n",
    "num_steps = 300\n",
    "thetaList = []\n",
    "\n",
    "for i in tqdm(range(num_episodes)):\n",
    "    # diminishing exploration rate\n",
    "    e = (0.8/num_episodes) * i + 0.1\n",
    "    \n",
    "    state = env.reset()\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    thetas = []\n",
    "\n",
    "    # sometimes random\n",
    "    mu_action = mu(state, θ) if np.random.uniform() < e else np.random.uniform(-1, 1, size=(1,))\n",
    "    for _ in range(num_steps):    \n",
    "        # TAKE ACTION\n",
    "        # gradient policy - sample\n",
    "        action = policy_approx(mu_action, σ, env)\n",
    "\n",
    "        new_state, reward, done, _ = env.step(mu_action)\n",
    "        # get next action using trained weights\n",
    "        mu_new_action = mu(new_state, θ)\n",
    "        \n",
    "        # convert reward to positive\n",
    "        reward *= -1\n",
    "\n",
    "        # learning parameters\n",
    "        if train:\n",
    "            dlogpi = state * ((action - mu_action)/σ**2)\n",
    "            θ = α * dlogpi * Q_approx(state, mu_action, w)\n",
    "            δ = reward + γ * Q_approx(new_state, mu_new_action, w) - Q_approx(state, mu_action, w)\n",
    "            w += β * δ * phi(state, mu_action)\n",
    "\n",
    "        # update state\n",
    "        state = new_state\n",
    "        mu_action = mu_new_action\n",
    "\n",
    "        # keep track of actions and rewards\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        thetas.append(Q_approx(state, mu_action, w))\n",
    "\n",
    "        if render:\n",
    "            env.render()\n",
    "\n",
    "        if done:\n",
    "            print(\"successful\")\n",
    "\n",
    "#         assert abs(mu_new_action) <= 2\n",
    "#         assert np.prod(abs(θ) < 100)\n",
    "#         assert np.prod(abs(w) < 100)\n",
    "            \n",
    "    env.close()\n",
    "    \n",
    "    thetaList.extend(thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu(state, θ):\n",
    "    return np.array([state @ θ])\n",
    "\n",
    "def policy_approx(mu_action, σ, env):\n",
    "    return np.clip(np.random.normal(mu_action, σ, size=(1,)), env.action_space.low[0], env.action_space.high[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 5/10000 [00:00<03:36, 46.08it/s]\u001b[A\n",
      "  0%|          | 11/10000 [00:00<03:30, 47.52it/s]\u001b[A\n",
      "  0%|          | 17/10000 [00:00<03:25, 48.70it/s]\u001b[A\n",
      "  0%|          | 22/10000 [00:00<03:25, 48.49it/s]\u001b[A\n",
      "  0%|          | 28/10000 [00:00<03:22, 49.26it/s]\u001b[A\n",
      "  0%|          | 33/10000 [00:00<03:21, 49.34it/s]\u001b[A\n",
      "  0%|          | 39/10000 [00:00<03:20, 49.80it/s]\u001b[A\n",
      "  0%|          | 44/10000 [00:00<03:22, 49.10it/s]\u001b[A\n",
      "  0%|          | 49/10000 [00:00<03:22, 49.04it/s]\u001b[A\n",
      "  1%|          | 54/10000 [00:01<03:45, 44.03it/s]\u001b[A\n",
      "  1%|          | 60/10000 [00:01<03:36, 45.91it/s]\u001b[A\n",
      "  1%|          | 66/10000 [00:01<03:30, 47.22it/s]\u001b[A\n",
      "  1%|          | 72/10000 [00:01<03:25, 48.38it/s]\u001b[A\n",
      "  1%|          | 77/10000 [00:01<03:26, 48.13it/s]\u001b[A\n",
      "  1%|          | 82/10000 [00:01<03:28, 47.59it/s]\u001b[A\n",
      "  1%|          | 88/10000 [00:01<03:25, 48.13it/s]\u001b[A\n",
      "  1%|          | 93/10000 [00:01<03:24, 48.36it/s]\u001b[A\n",
      "  1%|          | 98/10000 [00:02<03:23, 48.61it/s]\u001b[A\n",
      "  1%|          | 104/10000 [00:02<03:21, 49.15it/s]\u001b[A\n",
      "  1%|          | 109/10000 [00:02<03:21, 49.20it/s]\u001b[A\n",
      "  1%|          | 114/10000 [00:02<03:20, 49.37it/s]\u001b[A\n",
      "  1%|          | 119/10000 [00:02<03:20, 49.26it/s]\u001b[A\n",
      "  1%|▏         | 125/10000 [00:02<03:17, 49.92it/s]\u001b[A\n",
      "  1%|▏         | 131/10000 [00:02<03:15, 50.37it/s]\u001b[A\n",
      "  1%|▏         | 137/10000 [00:02<03:16, 50.28it/s]\u001b[A\n",
      "  1%|▏         | 143/10000 [00:02<03:17, 50.01it/s]\u001b[A\n",
      "  1%|▏         | 149/10000 [00:03<03:18, 49.63it/s]\u001b[A\n",
      "  2%|▏         | 154/10000 [00:03<03:19, 49.29it/s]\u001b[A\n",
      "  2%|▏         | 159/10000 [00:03<03:20, 49.11it/s]\u001b[A\n",
      "  2%|▏         | 164/10000 [00:03<03:19, 49.36it/s]\u001b[A\n",
      "  2%|▏         | 169/10000 [00:03<03:19, 49.39it/s]\u001b[A\n",
      "  2%|▏         | 175/10000 [00:03<03:17, 49.83it/s]\u001b[A\n",
      "  2%|▏         | 180/10000 [00:03<03:24, 48.14it/s]\u001b[A\n",
      "  2%|▏         | 185/10000 [00:03<03:22, 48.46it/s]\u001b[A\n",
      "  2%|▏         | 190/10000 [00:03<03:31, 46.32it/s]\u001b[A\n",
      "  2%|▏         | 195/10000 [00:03<03:27, 47.31it/s]\u001b[A\n",
      "  2%|▏         | 200/10000 [00:04<03:25, 47.66it/s]\u001b[A\n",
      "  2%|▏         | 205/10000 [00:04<03:43, 43.89it/s]\u001b[A\n",
      "  2%|▏         | 210/10000 [00:04<03:35, 45.52it/s]\u001b[A\n",
      "  2%|▏         | 215/10000 [00:04<03:37, 45.03it/s]\u001b[A\n",
      "  2%|▏         | 220/10000 [00:04<03:32, 46.06it/s]\u001b[A\n",
      "  2%|▏         | 225/10000 [00:04<03:49, 42.56it/s]\u001b[A\n",
      "  2%|▏         | 230/10000 [00:04<03:43, 43.72it/s]\u001b[A\n",
      "  2%|▏         | 235/10000 [00:04<03:35, 45.36it/s]\u001b[A\n",
      "  2%|▏         | 240/10000 [00:05<03:29, 46.55it/s]\u001b[A\n",
      "  2%|▏         | 245/10000 [00:05<03:26, 47.28it/s]\u001b[A\n",
      "  2%|▎         | 250/10000 [00:05<03:26, 47.13it/s]\u001b[A\n",
      "  3%|▎         | 255/10000 [00:05<03:24, 47.76it/s]\u001b[A\n",
      "  3%|▎         | 260/10000 [00:05<03:27, 46.85it/s]\u001b[A\n",
      "  3%|▎         | 265/10000 [00:05<03:30, 46.30it/s]\u001b[A\n",
      "  3%|▎         | 270/10000 [00:05<03:27, 46.87it/s]\u001b[A\n",
      "  3%|▎         | 275/10000 [00:05<03:29, 46.44it/s]\u001b[A\n",
      "  3%|▎         | 280/10000 [00:05<03:27, 46.86it/s]\u001b[A\n",
      "  3%|▎         | 286/10000 [00:05<03:22, 48.00it/s]\u001b[A\n",
      "  3%|▎         | 291/10000 [00:06<03:21, 48.27it/s]\u001b[A\n",
      "  3%|▎         | 296/10000 [00:06<03:21, 48.18it/s]\u001b[A\n",
      "  3%|▎         | 301/10000 [00:06<03:23, 47.55it/s]\u001b[A\n",
      "  3%|▎         | 306/10000 [00:06<03:22, 47.79it/s]\u001b[A\n",
      "  3%|▎         | 311/10000 [00:06<03:21, 48.01it/s]\u001b[A\n",
      "  3%|▎         | 316/10000 [00:06<03:21, 48.01it/s]\u001b[A\n",
      "  3%|▎         | 321/10000 [00:06<03:27, 46.69it/s]\u001b[A\n",
      "  3%|▎         | 326/10000 [00:06<03:36, 44.75it/s]\u001b[A\n",
      "  3%|▎         | 331/10000 [00:06<03:33, 45.23it/s]\u001b[A\n",
      "  3%|▎         | 336/10000 [00:07<03:30, 45.97it/s]\u001b[A\n",
      "  3%|▎         | 341/10000 [00:07<03:28, 46.40it/s]\u001b[A\n",
      "  3%|▎         | 346/10000 [00:07<03:24, 47.14it/s]\u001b[A\n",
      "  4%|▎         | 351/10000 [00:07<03:21, 47.79it/s]\u001b[A\n",
      "  4%|▎         | 356/10000 [00:07<03:25, 46.88it/s]\u001b[A\n",
      "  4%|▎         | 361/10000 [00:07<03:24, 47.10it/s]\u001b[A\n",
      "  4%|▎         | 366/10000 [00:07<03:24, 47.15it/s]\u001b[A\n",
      "  4%|▎         | 371/10000 [00:07<03:25, 46.96it/s]\u001b[A\n",
      "  4%|▍         | 376/10000 [00:07<03:24, 47.17it/s]\u001b[A\n",
      "  4%|▍         | 381/10000 [00:07<03:24, 47.07it/s]\u001b[A\n",
      "  4%|▍         | 386/10000 [00:08<03:22, 47.49it/s]\u001b[A\n",
      "  4%|▍         | 391/10000 [00:08<03:19, 48.08it/s]\u001b[A\n",
      "  4%|▍         | 396/10000 [00:08<03:18, 48.37it/s]\u001b[A\n",
      "  4%|▍         | 401/10000 [00:08<03:18, 48.29it/s]\u001b[A\n",
      "  4%|▍         | 406/10000 [00:08<03:18, 48.33it/s]\u001b[A\n",
      "  4%|▍         | 411/10000 [00:08<03:16, 48.70it/s]\u001b[A\n",
      "  4%|▍         | 416/10000 [00:08<03:17, 48.60it/s]\u001b[A\n",
      "  4%|▍         | 421/10000 [00:08<03:19, 48.10it/s]\u001b[A\n",
      "  4%|▍         | 426/10000 [00:08<03:18, 48.25it/s]\u001b[A\n",
      "  4%|▍         | 431/10000 [00:09<03:16, 48.71it/s]\u001b[A\n",
      "  4%|▍         | 437/10000 [00:09<03:16, 48.78it/s]\u001b[A\n",
      "  4%|▍         | 442/10000 [00:09<03:47, 41.97it/s]\u001b[A\n",
      "  4%|▍         | 447/10000 [00:09<03:39, 43.45it/s]\u001b[A\n",
      "  5%|▍         | 452/10000 [00:09<03:37, 43.90it/s]\u001b[A\n",
      "  5%|▍         | 457/10000 [00:09<03:34, 44.50it/s]\u001b[A\n",
      "  5%|▍         | 462/10000 [00:09<03:29, 45.57it/s]\u001b[A\n",
      "  5%|▍         | 467/10000 [00:09<03:29, 45.59it/s]\u001b[A\n",
      "  5%|▍         | 472/10000 [00:09<03:26, 46.04it/s]\u001b[A\n",
      "  5%|▍         | 477/10000 [00:10<03:31, 45.03it/s]\u001b[A\n",
      "  5%|▍         | 482/10000 [00:10<03:30, 45.17it/s]\u001b[A\n",
      "  5%|▍         | 487/10000 [00:10<03:29, 45.46it/s]\u001b[A\n",
      "  5%|▍         | 492/10000 [00:10<03:24, 46.38it/s]\u001b[A\n",
      "  5%|▍         | 497/10000 [00:10<03:21, 47.12it/s]\u001b[A\n",
      "  5%|▌         | 502/10000 [00:10<03:18, 47.95it/s]\u001b[A\n",
      "  5%|▌         | 507/10000 [00:10<03:17, 48.10it/s]\u001b[A\n",
      "  5%|▌         | 512/10000 [00:10<03:16, 48.34it/s]\u001b[A\n",
      "  5%|▌         | 517/10000 [00:10<03:15, 48.55it/s]\u001b[A\n",
      "  5%|▌         | 523/10000 [00:11<03:14, 48.71it/s]\u001b[A\n",
      "  5%|▌         | 528/10000 [00:11<03:17, 47.96it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-3e15aab99257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# TAKE ACTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# gradient policy - sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mmu_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mθ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0me\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mσ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 10000\n",
    "num_steps = 300\n",
    "\n",
    "α = 0.1\n",
    "θ = np.random.rand(2,)\n",
    "σ = 1\n",
    "γ = 0.8\n",
    "\n",
    "for i in tqdm(range(num_episodes)):\n",
    "    # diminishing exploration rate\n",
    "    e = (0.8/num_episodes) * i + 0.1\n",
    "    \n",
    "    state = env.reset()\n",
    "    rewards = []\n",
    "    mu_actions = []\n",
    "    actions = []\n",
    "    states = []\n",
    "\n",
    "    # sometimes random\n",
    "    for _ in range(num_steps):    \n",
    "        # TAKE ACTION\n",
    "        # gradient policy - sample\n",
    "        mu_action = mu(state, θ) if np.random.uniform() < e else np.random.uniform(-1, 1, size=(1,))\n",
    "        action = policy_approx(mu_action, σ, env)\n",
    "\n",
    "        states.append(state)\n",
    "        mu_actions.append(mu_action)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        assert abs(action) <= 1\n",
    "        assert abs(reward) < 1\n",
    "\n",
    "        # keep track of actions and rewards\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        if done:\n",
    "            print(\"done\")\n",
    "            # replay\n",
    "            state = env.reset()\n",
    "            for action in actions:\n",
    "                env.step(action)\n",
    "                env.render()\n",
    "\n",
    "            env.close()\n",
    "            raise Exception(\"\")\n",
    "            break\n",
    "        \n",
    "                        \n",
    "    # train\n",
    "    i = 0\n",
    "    for state, action, mu_action in zip(states, actions, mu_actions):\n",
    "        dlogpi = state * ((action - mu_action)/σ**2)\n",
    "        R = 0\n",
    "        for r in rewards[i:][::-1]:\n",
    "            R = r + γ * R\n",
    "        # minimise reward\n",
    "        θ = θ + α * dlogpi * R\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "θ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 528/10000 [00:25<03:17, 47.96it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "for action in actions:\n",
    "    env.step(action)\n",
    "    env.render()\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes random\n",
    "done = False\n",
    "state = env.reset()\n",
    "while not done:\n",
    "    # TAKE ACTION\n",
    "    # gradient policy - sample\n",
    "    mu_action = mu(state, θ)\n",
    "    action = policy_approx(mu_action, σ, env)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.005)\n",
    "    \n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu(state, θ):\n",
    "    return np.array([state @ θ])\n",
    "\n",
    "def policy_approx(mu_action, σ, env):\n",
    "    return np.clip(np.random.normal(mu_action, σ, size=(1,)), env.action_space.low[0], env.action_space.high[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(2,), Box(1,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 6/100 [00:00<00:01, 51.86it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -16.74805077381793 1.233394246917018\n",
      "not done -18.129011697181312 3.9401118588497073\n",
      "not done -19.177383894704068 26.630290032456717\n",
      "not done -17.834418604529922 546.6261285189524\n",
      "not done -17.989010354671503 6918.423584942755\n",
      "not done -18.53021263369004 124506.38999977185\n",
      "not done -19.134204275081633 2271636.9395728107\n",
      "not done -19.50529198683212 46154337.871301144\n",
      "not done -20.13142425924694 1137501672.062231\n",
      "not done -18.735265884781132 30961301935.915325\n",
      "not done -19.969549498111896 696914337113.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|█▏        | 12/100 [00:00<00:01, 51.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 17/100 [00:00<00:01, 51.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 23/100 [00:00<00:01, 51.81it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -19.185258061127712 24225544817011.64\n",
      "not done -20.332916510169973 556574815925400.6\n",
      "not done -18.647817010782934 1.7997290351230952e+16\n",
      "not done -18.657605587453176 4.5093716216765805e+17\n",
      "not done -19.408456624155434 1.264090676264891e+19\n",
      "not done -19.49897674213282 4.378131147557734e+20\n",
      "not done -20.49379621852876 1.5466481951205147e+22\n",
      "not done -20.353715259629812 5.646995490334824e+23\n",
      "not done -20.03884384710873 1.9126525533422827e+25\n",
      "not done -20.3184299974841 7.921376450929932e+26\n",
      "not done -19.839084613356807 3.063735362361651e+28\n",
      "not done -20.44013451169417 9.932756179532377e+29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|██▊       | 28/100 [00:00<00:01, 51.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 34/100 [00:00<00:01, 50.83it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -20.04075299843055 3.518131692492725e+31\n",
      "not done -21.123389188070153 1.410613814979247e+33\n",
      "not done -21.283571509573342 5.854956046135888e+34\n",
      "not done -21.68841660256954 2.5193203391103974e+36\n",
      "not done -22.678707654675012 1.0624026476706032e+38\n",
      "not done -21.513647893046564 6.074384215164577e+39\n",
      "not done -20.078712301429988 2.929076854305714e+41\n",
      "not done -22.761439443450524 1.2517674726859492e+43\n",
      "not done -21.939230929752107 6.396727684343452e+44\n",
      "not done -21.305016976180568 3.480694739901344e+46\n",
      "not done -21.84869327927837 1.7995216513957124e+48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|████      | 40/100 [00:00<00:01, 50.95it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -21.895118717003992 7.625601343993035e+49\n",
      "not done -22.466257730879875 4.0810492740573116e+51\n",
      "not done -22.622522135655537 2.162239331061987e+53\n",
      "not done -21.730205055495166 1.1172669221587132e+55\n",
      "not done -22.971100304744464 5.944857855198022e+56\n",
      "not done -23.343924522935872 3.588255568112727e+58\n",
      "not done -21.687457498821995 2.2604737484884866e+60\n",
      "not done -22.20372561219976 1.2088295418724025e+62\n",
      "not done -21.7058120698849 6.634900262630296e+63\n",
      "not done -22.95277295705212 3.7363920566369803e+65\n",
      "not done -22.687285945269686 2.4517156793267295e+67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 46%|████▌     | 46/100 [00:00<00:01, 51.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 52/100 [00:01<00:00, 50.88it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -23.195387251710446 1.4530075610907567e+69\n",
      "not done -23.690087714150465 9.086580994192378e+70\n",
      "not done -22.11417369775364 6.2731579131170455e+72\n",
      "not done -24.349054502984224 3.431911768366452e+74\n",
      "not done -24.42402724936077 2.839193587295447e+76\n",
      "not done -24.723393235864567 1.9877802436985825e+78\n",
      "not done -23.892122906495278 1.6883754456276832e+80\n",
      "not done -23.0128713771504 1.1828606372176138e+82\n",
      "not done -23.47928777226786 7.945321911945831e+83\n",
      "not done -23.13547021895887 6.093332954594699e+85\n",
      "not done -23.08762986945904 3.6616112943708203e+87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 57%|█████▋    | 57/100 [00:01<00:00, 50.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 63/100 [00:01<00:00, 50.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -24.494979534679523 2.4258832415581341e+89\n",
      "not done -24.66312416247243 1.6077819897583078e+91\n",
      "not done -24.058442714997526 1.4829838262039137e+93\n",
      "not done -24.225846530645118 9.549057431869909e+94\n",
      "not done -25.271794798705418 6.81910745534636e+96\n",
      "not done -26.137149945343918 5.435689101426617e+98\n",
      "not done -24.604065399454655 4.068820443103317e+100\n",
      "not done -24.93973656601131 2.917865316973786e+102\n",
      "not done -24.963409764477642 2.6121488821548336e+104\n",
      "not done -25.969216790590874 1.7420613765264394e+106\n",
      "not done -25.33578442056387 1.3736525259193911e+108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|██████▊   | 68/100 [00:01<00:00, 49.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 73/100 [00:01<00:00, 49.14it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -24.785876757648897 1.1220377335576637e+110\n",
      "not done -25.578092739502306 8.742018405837738e+111\n",
      "not done -25.38419263944214 7.520192233413964e+113\n",
      "not done -25.04293246068911 6.017127876852775e+115\n",
      "not done -24.94028530659065 4.9619918645506975e+117\n",
      "not done -25.568621257507225 4.229036198231918e+119\n",
      "not done -25.427501650061505 3.3252040176413373e+121\n",
      "not done -24.263875350857607 2.550073115126443e+123\n",
      "not done -25.373538275934003 1.918985152936047e+125\n",
      "not done -26.742140854583422 1.5410132519764395e+127\n",
      "not done -26.434150696970626 1.2896642137656785e+129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [00:01<00:00, 49.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 84/100 [00:01<00:00, 49.94it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -26.647557352469633 1.1888120488306058e+131\n",
      "not done -26.530653277686724 1.1849424947260503e+133\n",
      "not done -26.43232637596304 1.0712039451999796e+135\n",
      "not done -26.376949443319 8.378789207291082e+136\n",
      "not done -27.363089763996868 7.141064868174264e+138\n",
      "not done -26.132632424346898 6.276351555171364e+140\n",
      "not done -27.45707585116785 5.107114006865082e+142\n",
      "not done -26.78962801628681 4.77302403709278e+144\n",
      "not done -27.903883115115462 4.259330412473467e+146\n",
      "not done -27.557989014733828 3.795562831298436e+148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 89%|████████▉ | 89/100 [00:01<00:00, 47.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 95/100 [00:01<00:00, 49.30it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -27.750329201286238 3.38791339136729e+150\n",
      "not done -27.0808892379263 3.0132666253151885e+152\n",
      "not done -27.719267617546222 inf\n",
      "not done -27.53100343547358 inf\n",
      "not done -27.864212568820946 inf\n",
      "not done -27.783338271842748 inf\n",
      "not done -27.86551387735264 inf\n",
      "not done -28.51110555088399 inf\n",
      "not done -28.292558512696267 inf\n",
      "not done -28.449992494206317 inf\n",
      "not done -28.33462131802401 inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.09it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done -28.74566964147958 inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.35689828e+174,  2.69636911e+171,  2.69636911e+171,\n",
       "        1.02270050e+171])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "num_steps = 300\n",
    "\n",
    "α = 0.1\n",
    "θ = np.random.rand(4,)\n",
    "σ = 1\n",
    "γ = 0.8\n",
    "\n",
    "for i in tqdm(range(num_episodes)):\n",
    "    # diminishing exploration rate\n",
    "    e = (0.8/num_episodes) * i + 0.1\n",
    "    \n",
    "    rewards = []\n",
    "    mu_actions = []\n",
    "    actions = []\n",
    "    states = []\n",
    "\n",
    "    state = np.concatenate((env.reset(), np.array([0, 0])))\n",
    "#     mu_action = np.random.uniform(-1, 1, size=(1,))\n",
    "    mu_action = mu(state, θ) if np.random.uniform() < e else np.random.uniform(-1, 1, size=(1,))\n",
    "\n",
    "    # sometimes random\n",
    "    for _ in range(num_steps):    \n",
    "        action = policy_approx(mu_action, σ, env)\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        diff = new_state - state[:2]\n",
    "        state = np.concatenate((new_state, diff))\n",
    "    \n",
    "        # state includes diff\n",
    "        states.append(state)\n",
    "        mu_actions.append(mu_action)\n",
    "        actions.append(action)\n",
    "        \n",
    "        # keep track of actions and rewards\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        if done:\n",
    "            print(\"done\")\n",
    "#             # replay\n",
    "#             state = env.reset()\n",
    "#             for action in actions:\n",
    "#                 env.step(action)\n",
    "#                 env.render()\n",
    "\n",
    "#             env.close()\n",
    "#             raise Exception(\"\")\n",
    "            break\n",
    "            \n",
    "        mu_action = mu(state, θ) if np.random.uniform() < e else np.random.uniform(-1, 1, size=(1,))\n",
    "        \n",
    "#         assert abs(mu_action) < 2\n",
    "\n",
    "        \n",
    "    if done:\n",
    "        print(\"done\", sum(rewards), np.linalg.norm(θ))\n",
    "    else:\n",
    "        print(\"not done\", sum(rewards), np.linalg.norm(θ))\n",
    "                        \n",
    "    # train minimise reward\n",
    "    for state, action, mu_action in zip(states, actions, mu_actions):\n",
    "        mu_action = abs(mu_action) if mu_action < -1 else mu_action\n",
    "        dlogpi = state * ((action - mu_action)/σ**2)\n",
    "        θ = θ + α * dlogpi * sum(rewards)\n",
    "    \n",
    "#     i = 0\n",
    "#     for state, action, mu_action in zip(states, actions, mu_actions):\n",
    "#         dlogpi = state * ((action - mu_action)/σ**2)\n",
    "#         R = 0\n",
    "#         for r in rewards[i:][::-1]:\n",
    "#             R = r + γ * R\n",
    "#         # minimise reward\n",
    "#         θ = θ - α * dlogpi * R\n",
    "\n",
    "#         i += 1\n",
    "        \n",
    "θ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for action in actions:\n",
    "    env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.005)\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes random\n",
    "done = False\n",
    "state = np.concatenate((env.reset(), np.array([0, 0])))\n",
    "# mu_action = np.random.uniform(-1, 1, size=(1,))\n",
    "mu_action = mu(state, θ)\n",
    "for _ in range(num_steps): \n",
    "    action = policy_approx(mu_action, σ, env)\n",
    "    new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    diff = new_state - state[:2]\n",
    "    state = np.concatenate((new_state, diff))\n",
    "\n",
    "    mu_action = mu(state, θ) #if np.random.uniform() < 0.3 else np.random.uniform(-1, 1, size=(1,))\n",
    "    \n",
    "    env.render()\n",
    "    time.sleep(0.005)\n",
    "    \n",
    "    if done:\n",
    "        print(\"done\")\n",
    "        break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.2800193 , 0.05769776], dtype=float32),\n",
       " 400,\n",
       " array([-1.02214268e-01,  9.10168543e-02,  1.01379090e-01, -1.41332601e-01,\n",
       "         2.93913883e-02,  1.39476665e-01,  1.95481497e-02,  1.04866269e-01,\n",
       "        -1.41376966e-01, -6.05327312e-02,  1.34208409e-04, -1.37791173e-01,\n",
       "        -8.28713953e-02,  2.93601850e-02,  9.67093197e-02, -1.36176980e-01,\n",
       "        -1.16757212e-01,  5.45302113e-02,  4.22399678e-02, -2.86192697e-02,\n",
       "         1.22874267e-01,  9.81621030e-02, -1.38032889e-01,  1.21929988e-01,\n",
       "         1.31356573e-01,  1.30028255e-01, -1.39268045e-01,  1.04703258e-01,\n",
       "         1.41417678e-01, -1.33806642e-01, -4.34702387e-02, -1.40373701e-01,\n",
       "        -7.25861297e-02, -9.84651844e-02,  1.08626791e-01,  6.50991227e-02,\n",
       "         1.24387060e-01,  1.36417675e-01,  1.33312870e-01, -1.71161794e-02,\n",
       "        -7.02103764e-02, -1.36140019e-01,  5.43915250e-02, -9.79312036e-02,\n",
       "         1.28723526e-01,  7.76717552e-02, -6.37048887e-02,  5.29013539e-02,\n",
       "        -1.41262207e-01, -1.34632218e-01,  1.41420889e-01, -1.21811477e-01,\n",
       "        -2.62030811e-02,  7.38673733e-02, -1.34739365e-01, -1.23803540e-01,\n",
       "        -1.27146433e-01, -1.17455740e-01, -1.40160343e-01, -1.04429905e-01,\n",
       "         2.56649537e-02,  4.17494732e-02, -1.40605284e-01,  4.11453755e-02,\n",
       "         3.77696162e-02,  1.44293284e-02,  1.40876246e-01, -2.24170311e-03,\n",
       "        -1.39505120e-01,  1.62863947e-02, -1.00755617e-01,  9.29346967e-02,\n",
       "        -1.19475432e-01,  8.01141838e-02,  7.13006041e-02, -3.70692755e-02,\n",
       "         7.62903348e-02, -7.80254916e-02, -2.42770841e-02,  3.13300771e-02,\n",
       "        -3.42057562e-02, -9.42643632e-02, -1.40831180e-01, -2.42339362e-02,\n",
       "         1.38836494e-01,  8.35203318e-02, -8.59652286e-02, -1.40235768e-01,\n",
       "         9.37456558e-02,  7.29664707e-02, -1.18345924e-01, -1.40347309e-01,\n",
       "         8.16968726e-02, -3.04482515e-03,  1.25496235e-01, -1.15946355e-02,\n",
       "        -1.40572880e-01,  7.76014411e-03,  9.86085788e-02,  1.07946631e-01,\n",
       "         1.13059211e-01,  1.10672432e-01, -4.53037638e-02,  2.81278721e-02,\n",
       "         1.20706073e-01, -1.21156968e-01, -1.29804131e-01,  1.41393895e-01,\n",
       "         3.58773205e-02,  1.05473353e-01, -1.11835298e-01,  1.16119278e-01,\n",
       "         1.08162141e-01,  1.35290118e-01, -2.84426044e-02,  6.68910448e-02,\n",
       "        -1.03246716e-01, -1.48801076e-02,  1.07083532e-01, -1.31659239e-01,\n",
       "        -1.31752057e-01, -1.03118191e-02,  4.81703295e-02, -2.53670668e-02,\n",
       "         3.66548839e-02, -1.33415112e-01,  8.62086027e-02,  1.41311633e-01,\n",
       "        -1.39192478e-01, -7.62605290e-02, -1.64665258e-02,  1.03242960e-01,\n",
       "         1.08375233e-01, -1.70256737e-02, -9.69256904e-02,  5.45080500e-02,\n",
       "         7.65876878e-02, -1.12604671e-01, -2.85780377e-02,  1.50288169e-02,\n",
       "         7.48610995e-02,  4.32766332e-02,  6.61846968e-02, -2.88180446e-03,\n",
       "        -1.14157525e-01, -1.15882045e-01,  1.41413988e-01,  6.73418445e-02,\n",
       "        -8.11123077e-02, -1.39135462e-01,  1.37691908e-01, -8.44958997e-02,\n",
       "        -1.41405936e-01,  9.13746919e-02,  4.42276652e-02, -2.51905516e-02,\n",
       "        -1.01609368e-01, -1.69348434e-02, -1.32392061e-01, -1.03490196e-02,\n",
       "         1.39613704e-01,  1.34630993e-01, -1.54176940e-02, -1.25849319e-01,\n",
       "        -1.38386991e-01, -1.41242704e-01, -2.00984118e-02, -7.87453985e-03,\n",
       "        -1.30366284e-01,  1.36370580e-01, -7.46667809e-02,  1.25316679e-01,\n",
       "        -1.60309502e-02, -1.38545617e-01,  4.21053221e-02, -9.15110896e-02,\n",
       "        -9.16469212e-02,  1.42256397e-02,  1.19423754e-01, -1.39085288e-01,\n",
       "        -2.22418069e-02,  1.36149705e-01, -1.10508629e-02,  1.38390482e-01,\n",
       "         1.26596126e-01, -9.32474266e-02,  1.23066625e-01,  7.46507725e-02,\n",
       "         4.50940389e-02,  4.51268012e-02, -1.03041719e-01, -1.20067892e-01,\n",
       "        -8.50072121e-02,  1.34057179e-01,  1.25118679e-01, -1.32285353e-01,\n",
       "         1.40067726e-01, -3.93525082e-02, -1.33296155e-01, -9.72512278e-02,\n",
       "        -2.99235833e-02, -3.21571470e-02,  2.57698259e-02, -1.38673202e-01,\n",
       "        -1.40805310e-01, -1.41385273e-01, -3.06015724e-02,  5.23385310e-02,\n",
       "        -8.27570313e-02, -4.77077467e-02,  1.41042223e-01, -4.05443358e-02,\n",
       "         1.15591876e-01,  1.34565373e-01, -1.12049516e-01, -1.37163856e-01,\n",
       "         1.12143309e-02, -3.32713603e-02,  4.28793507e-03, -6.89177423e-04,\n",
       "         1.24938464e-01, -1.37777153e-01,  6.41013993e-02,  1.08794256e-01,\n",
       "        -1.40560267e-01,  1.41274549e-01,  1.38931495e-01, -1.10275873e-02,\n",
       "        -1.04985563e-02, -2.59449484e-02, -1.41414955e-01, -1.39054135e-01,\n",
       "         1.41282063e-01,  3.89399576e-03,  1.06785938e-01,  1.20149212e-01,\n",
       "         1.30096064e-01,  8.36822636e-02,  8.54681198e-03, -1.41045864e-01,\n",
       "         9.99195482e-02, -9.18637348e-02,  1.16213552e-01,  1.33734638e-01,\n",
       "        -1.26388802e-01, -3.06472782e-02, -1.26067698e-01,  9.72924725e-02,\n",
       "         1.26092883e-02, -6.19696389e-03,  1.41255380e-01, -5.64996430e-02,\n",
       "        -4.03589902e-02, -1.04699127e-01,  3.50367244e-02, -1.03841465e-01,\n",
       "         9.28788780e-02,  1.32674032e-01,  1.12615359e-01, -1.36765497e-01,\n",
       "        -1.40625616e-01,  8.58186649e-02,  6.76192965e-03, -6.32669335e-02,\n",
       "        -1.86470283e-02, -7.58267092e-02, -7.17365269e-03, -1.27418100e-01,\n",
       "        -1.13230298e-01,  1.16441268e-01, -1.26602875e-01,  1.20617213e-01,\n",
       "        -1.40156311e-01,  8.99166359e-02, -8.25901860e-02,  8.06808375e-02,\n",
       "        -1.30241022e-01, -4.56204400e-02,  1.41379625e-01, -4.17035536e-02,\n",
       "         1.00164536e-01,  5.27511535e-02,  1.18331198e-01, -1.15444286e-01,\n",
       "         5.96714077e-02,  1.23193023e-01, -3.83257066e-02, -1.40711228e-01,\n",
       "         1.20340469e-01,  9.52850810e-02,  8.10936660e-02, -4.47018980e-02,\n",
       "         1.38014405e-01, -1.19624877e-01, -1.40101929e-01, -5.44228996e-02,\n",
       "        -1.10488471e-01,  2.93593922e-02, -1.36619234e-01, -1.30057027e-01,\n",
       "         9.17933730e-02, -1.00165039e-01,  1.60732750e-02, -9.46631604e-02,\n",
       "        -1.38042065e-01, -1.41355686e-01,  2.76886132e-02, -1.41396669e-01,\n",
       "         2.19749813e-02,  8.36895117e-02, -1.34903318e-01, -3.68202541e-02,\n",
       "        -1.02216978e-01, -2.79296601e-02,  1.03165446e-01,  1.36314624e-01,\n",
       "         7.20351134e-02, -4.60128896e-02, -7.69047476e-02,  1.20530089e-01,\n",
       "         9.58187493e-02,  7.02089688e-02, -9.76741335e-06,  9.30645726e-02,\n",
       "         1.40796392e-01, -1.04545463e-01, -4.90671614e-03, -1.25863275e-01,\n",
       "        -4.86947338e-02,  1.16066596e-02, -8.55246211e-02,  9.29796189e-02,\n",
       "         8.98623962e-02,  7.90850599e-02, -1.36151520e-01, -1.29635123e-01,\n",
       "        -6.30839250e-02, -1.40527955e-01,  1.26173895e-01, -1.61763814e-02,\n",
       "         2.15265378e-03, -7.86087390e-02, -1.14544709e-01,  8.27296406e-02,\n",
       "         1.38139265e-01,  3.25314330e-02,  1.07990999e-01, -1.41414442e-01,\n",
       "        -1.37994755e-01, -1.29470096e-01,  1.12525072e-01, -6.11712225e-02,\n",
       "        -2.47048529e-02, -9.23242478e-02, -8.00476642e-02, -1.29538952e-01,\n",
       "        -1.38080055e-01, -2.66887244e-02, -1.13726913e-01,  1.05962211e-01,\n",
       "        -4.05701886e-02,  9.27914231e-02,  5.55321729e-02, -1.16601240e-01,\n",
       "        -1.36196974e-01,  9.55038226e-02,  1.10132747e-01, -8.16093439e-02,\n",
       "        -1.41306942e-01, -1.09117199e-01, -1.15958478e-01, -1.38474908e-01,\n",
       "        -7.95227414e-02,  5.68135034e-03, -1.39703800e-01,  1.12836714e-02,\n",
       "         9.82070726e-02, -1.40653470e-01,  5.78750045e-03,  1.34814151e-01,\n",
       "        -1.06084585e-01,  6.21917661e-02, -1.41357655e-01, -1.05340753e-01,\n",
       "         1.28404436e-01, -9.66148952e-02, -6.95243671e-02,  5.58580162e-02,\n",
       "        -1.19153461e-01,  5.47354625e-03, -1.39316989e-01, -1.34586012e-01,\n",
       "         4.34935913e-03,  1.92339719e-02,  5.37368026e-02,  1.40556169e-01,\n",
       "         1.21575094e-01, -4.63678451e-02, -1.14986863e-01,  1.41405225e-01]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(observation_examples)\n",
    "\n",
    "# Used to converte a state to a featurizes represenation.\n",
    "# We use RBF kernels with different variances to cover different parts of the space\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "        (\"rbf1\", RBFSampler(gamma=5.0, n_components=100)),\n",
    "        (\"rbf2\", RBFSampler(gamma=2.0, n_components=100)),\n",
    "        (\"rbf3\", RBFSampler(gamma=1.0, n_components=100)),\n",
    "        (\"rbf4\", RBFSampler(gamma=0.5, n_components=100))\n",
    "        ])\n",
    "featurizer.fit(scaler.transform(observation_examples))\n",
    "\n",
    "def featurize_state(state):\n",
    "    \"\"\"\n",
    "    Returns the featurized representation for a state.\n",
    "    \"\"\"\n",
    "    scaled = scaler.transform([state])\n",
    "    featurized = featurizer.transform(scaled)\n",
    "    return featurized[0]\n",
    "\n",
    "state = env.observation_space.sample()\n",
    "featState = featurize_state(state)\n",
    "state, len(featState), featState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 1/10 [00:00<00:01,  5.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 2/10 [00:00<00:01,  5.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.24it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6.08328959e+26, -1.85805726e+26,  8.50762986e+26,  1.00253944e+27,\n",
       "       -1.08845524e+27,  1.51516845e+26,  4.95188248e+26,  7.92468584e+26,\n",
       "        5.73051834e+26, -9.75896230e+26,  2.95974368e+26, -3.12469319e+25,\n",
       "       -1.84534288e+26, -2.29740703e+26, -1.91736007e+26, -1.96955533e+26,\n",
       "        8.04596676e+25,  6.70508477e+25, -7.56034292e+26,  6.32639151e+26,\n",
       "        1.02487732e+27, -5.11286116e+26, -1.64554115e+26,  6.35927638e+26,\n",
       "       -6.45490669e+26,  5.19082855e+26,  4.40992396e+26, -8.02255684e+25,\n",
       "        3.71914562e+26, -2.65434767e+26, -9.54874483e+26, -6.63951482e+26,\n",
       "        5.51222306e+26, -7.99700431e+25,  1.12765380e+26,  1.05039457e+27,\n",
       "        4.71671532e+26,  5.03587524e+26, -2.99372284e+26, -9.75017212e+26,\n",
       "       -8.51201366e+26, -2.87381982e+26,  3.46525630e+26, -7.34881558e+26,\n",
       "        6.44159238e+26,  2.24373581e+26,  1.01660290e+27,  6.97961644e+26,\n",
       "       -3.91404341e+26, -1.18560499e+26,  7.37182533e+26, -6.14799276e+26,\n",
       "        6.00370080e+26, -8.31908553e+25, -3.71785824e+25, -3.94053723e+26,\n",
       "        1.92020552e+26,  5.87108705e+25,  7.59625305e+25,  7.59179171e+26,\n",
       "        1.27163238e+26,  1.94004662e+26,  1.01894027e+27, -2.84650176e+26,\n",
       "        6.95206078e+26,  9.75569683e+26,  9.22575357e+26, -1.52482650e+25,\n",
       "        3.92672115e+26, -1.62215777e+26, -5.47799699e+26, -7.87945573e+26,\n",
       "       -7.02520765e+26,  6.91720709e+26, -2.47493331e+26,  1.11014391e+27,\n",
       "       -9.13896305e+25,  5.65552296e+26, -7.12904169e+26,  7.04959193e+26,\n",
       "       -3.95321672e+26, -6.22095968e+26, -2.90082718e+26,  3.45971547e+26,\n",
       "       -7.08757696e+26,  2.98988966e+26, -1.11202786e+27, -2.89830208e+26,\n",
       "        7.89109623e+26,  8.17495559e+26, -7.02883599e+26,  4.13680523e+26,\n",
       "        9.04387325e+25,  5.08198318e+26, -3.01298284e+26,  3.57983820e+26,\n",
       "       -6.70120901e+25, -5.39693493e+26,  9.54061325e+26, -4.72885481e+26,\n",
       "       -7.76173595e+26, -4.95790062e+26, -8.45047358e+25, -2.74776029e+26,\n",
       "       -6.89088995e+26,  2.61666405e+26,  4.42324955e+26,  8.79707920e+26,\n",
       "       -9.97302268e+26,  7.41799419e+25, -1.07056067e+27, -7.92547060e+26,\n",
       "       -4.83186996e+26,  8.57030929e+25, -6.94783189e+26, -9.33707820e+26,\n",
       "       -1.04529640e+25,  6.64479967e+26,  8.77808323e+26, -7.86026659e+26,\n",
       "        9.28666238e+26, -6.00106817e+25, -5.14764486e+26, -2.88335223e+26,\n",
       "       -2.74211824e+26,  1.01844278e+27, -8.05267472e+26, -1.02069623e+27,\n",
       "       -7.45999787e+25, -4.54598498e+26,  9.49187115e+26, -1.06020340e+27,\n",
       "        1.02655383e+27, -7.02107828e+26, -9.37628694e+26,  3.83131885e+26,\n",
       "       -6.44201680e+26, -9.77865370e+26, -9.39402791e+26, -9.36286730e+26,\n",
       "        6.35013889e+25, -7.34509115e+26,  5.28255302e+26, -1.48739475e+26,\n",
       "       -7.68834373e+26, -9.59219185e+26,  7.31190494e+26,  7.29580629e+26,\n",
       "        6.97675438e+26,  1.09657548e+27,  6.63674687e+26, -9.27409546e+25,\n",
       "       -1.61054229e+26, -4.49231753e+26, -2.63136708e+26, -3.82488787e+26,\n",
       "        2.95964101e+26, -9.39432656e+26, -1.08112900e+26, -1.75512153e+26,\n",
       "       -7.50722346e+25, -9.42732978e+26,  1.05843907e+27, -9.15519563e+26,\n",
       "       -5.25226314e+26, -1.64146145e+26,  7.65265512e+26,  1.40782883e+26,\n",
       "        8.02192226e+26,  1.12190969e+27,  1.07033138e+27,  1.61952835e+26,\n",
       "        9.04615456e+26,  4.50866554e+26, -9.59134205e+26, -4.05449826e+26,\n",
       "       -6.70042952e+26,  5.33382268e+26, -4.35223433e+26, -1.12310972e+27,\n",
       "       -9.83940119e+25,  9.21889960e+26, -1.07486393e+27,  1.11267566e+27,\n",
       "       -9.26806778e+26,  1.09654462e+27,  8.30796403e+26, -6.66568617e+26,\n",
       "       -1.07380004e+27, -9.35089617e+26, -7.78557895e+25,  8.43316962e+26,\n",
       "        9.78743295e+26,  3.58785227e+26, -9.05368016e+26,  9.08159930e+26,\n",
       "        1.13563718e+27, -5.05807078e+26, -7.13033512e+26,  1.00510105e+27,\n",
       "       -6.39751415e+26, -5.13028917e+26, -1.06797090e+27, -9.80958299e+26,\n",
       "        7.02693205e+25, -1.07022530e+26, -1.13703475e+27,  1.01003836e+27,\n",
       "        7.86410174e+26,  1.10516712e+27,  1.95462332e+26, -1.82101814e+26,\n",
       "       -2.19019406e+26,  7.84594398e+26,  8.17424242e+26, -1.81682300e+26,\n",
       "       -1.01244948e+27, -7.06508894e+26,  3.20141546e+26, -2.72391139e+26,\n",
       "        9.06008860e+26, -1.59866899e+26, -8.70010342e+26, -9.80565516e+25,\n",
       "       -1.12665343e+27,  7.06067766e+26,  9.02929143e+25, -2.66004734e+26,\n",
       "        6.17747830e+26,  3.65082398e+26,  7.45260234e+26, -9.82176298e+26,\n",
       "       -4.31324922e+26,  9.28081016e+26,  8.95968460e+26,  1.06151019e+27,\n",
       "       -9.59034954e+26, -8.66802513e+26, -1.49232978e+25, -1.15245574e+27,\n",
       "        8.59977488e+26, -5.53863539e+26, -2.44607099e+26,  8.40288732e+26,\n",
       "       -1.17237418e+26,  5.46592007e+26,  9.48983426e+26, -6.75476249e+26,\n",
       "       -8.20106572e+26, -7.56579845e+26, -2.44543798e+26,  2.45105053e+26,\n",
       "       -1.07666026e+27,  6.43142005e+25,  6.11702868e+26,  8.30311576e+26,\n",
       "        9.57792887e+26, -9.18759649e+26,  7.17280577e+26, -7.31859387e+26,\n",
       "        8.73040107e+26, -9.33816390e+26,  6.85577983e+26,  2.98497562e+26,\n",
       "       -3.11825028e+26,  9.90110029e+26,  5.95860309e+25, -1.06719011e+27,\n",
       "        4.39317462e+25, -2.73352962e+26,  7.72438815e+26,  8.17732815e+26,\n",
       "        6.55342559e+26,  5.41039528e+26,  1.10975821e+27,  1.06979536e+27,\n",
       "       -1.14216057e+27, -9.95969642e+26,  2.44359633e+25, -7.97411295e+26,\n",
       "        2.09412961e+26, -4.20975683e+26,  9.61790222e+26, -1.02103166e+27,\n",
       "       -1.06228271e+27,  3.90166052e+26, -9.33467791e+26, -9.08008648e+26,\n",
       "       -8.48313108e+26,  1.01642689e+27, -7.58708759e+26, -3.01511526e+26,\n",
       "       -3.29191215e+26, -3.31409566e+25,  2.18308488e+26,  1.13452145e+27,\n",
       "        4.39801627e+26, -7.84820783e+26, -3.88237795e+26,  9.52601253e+26,\n",
       "       -8.67605762e+26,  4.18087802e+26,  8.60251690e+26,  7.13461249e+26,\n",
       "       -1.07034904e+27,  9.14926381e+25,  1.14439995e+27, -7.78729945e+26,\n",
       "        1.03251110e+27,  1.28888701e+26,  9.18395085e+26, -5.06621640e+26,\n",
       "        7.54547267e+26, -3.30949274e+26,  4.73555652e+26,  1.05786548e+27,\n",
       "       -4.35299807e+26,  4.57766538e+26, -5.86545725e+26,  1.11356912e+27,\n",
       "       -7.65070876e+26, -1.12912122e+27,  2.79768178e+26, -4.29505245e+26,\n",
       "        4.41407778e+26, -8.72689839e+26,  4.88098188e+26,  1.02908235e+27,\n",
       "        1.14553594e+27,  5.50941891e+26, -3.49662559e+26,  4.40613717e+26,\n",
       "        1.03906359e+27, -7.04195186e+26, -4.72160728e+26, -1.14154885e+27,\n",
       "        9.67643506e+26, -3.46100393e+26, -4.20325195e+26, -5.20911041e+26,\n",
       "        1.08902150e+27, -4.45046913e+26,  5.32872174e+26,  1.11129133e+27,\n",
       "        2.76810653e+26,  6.29472043e+26,  2.60591150e+26, -2.10630309e+26,\n",
       "       -3.42798092e+26,  1.06516810e+27,  1.15869268e+27, -8.84319137e+26,\n",
       "        2.52340698e+26, -9.58984913e+26, -1.07251881e+27,  3.73124104e+25,\n",
       "       -1.15178807e+27,  3.63471613e+26,  8.65863665e+26, -1.07439019e+27,\n",
       "        1.11075670e+27,  3.53601606e+26, -3.09931395e+26,  7.49803105e+26,\n",
       "        6.05971977e+26,  7.70094602e+26,  7.81905873e+26,  1.62137391e+26,\n",
       "       -9.36920447e+26,  4.88282367e+26, -1.11325800e+27, -5.38877811e+26,\n",
       "       -1.12173592e+27, -6.04040631e+26,  9.69325674e+26,  1.00538273e+27,\n",
       "       -9.08601878e+26,  1.08610233e+27,  9.75217494e+25,  3.15175761e+26,\n",
       "        1.01718214e+27,  5.76827642e+26,  1.10178133e+27,  5.65271817e+26,\n",
       "        1.08820971e+27, -8.68399893e+26, -1.15062477e+27,  2.44370511e+26,\n",
       "        1.10368312e+27,  6.46228621e+26, -6.82120119e+25, -9.44730759e+26,\n",
       "       -9.46061413e+26, -1.15186941e+27, -1.09100051e+27,  3.79182190e+26,\n",
       "        2.34585473e+26, -7.77662144e+26, -1.57282482e+26, -7.54520604e+26])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "num_steps = 300\n",
    "\n",
    "α = 0.1\n",
    "θ = np.random.rand(400,)\n",
    "σ = 1\n",
    "γ = 0.8\n",
    "\n",
    "for i in tqdm(range(num_episodes)):\n",
    "    # diminishing exploration rate\n",
    "    e = (0.8/num_episodes) * i + 0.1\n",
    "    \n",
    "    rewards = []\n",
    "    mu_actions = []\n",
    "    actions = []\n",
    "    states = []\n",
    "\n",
    "    state = env.reset()\n",
    "    state = featurize_state(state)\n",
    "    \n",
    "    mu_action = mu(state, θ) if np.random.uniform() < e else np.random.uniform(-1, 1, size=(1,))\n",
    "\n",
    "    # sometimes random\n",
    "    for _ in range(num_steps):    \n",
    "        action = policy_approx(mu_action, σ, env)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "\n",
    "        state = featurize_state(state)\n",
    "    \n",
    "        # state includes diff\n",
    "        states.append(state)\n",
    "        mu_actions.append(mu_action)\n",
    "        actions.append(action)\n",
    "        \n",
    "        # keep track of actions and rewards\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        if done:\n",
    "            print(\"done\")\n",
    "#             # replay\n",
    "#             state = env.reset()\n",
    "#             for action in actions:\n",
    "#                 env.step(action)\n",
    "#                 env.render()\n",
    "\n",
    "#             env.close()\n",
    "#             raise Exception(\"\")\n",
    "            break\n",
    "            \n",
    "        mu_action = mu(state, θ) if np.random.uniform() < e else np.random.uniform(-1, 1, size=(1,))\n",
    "        \n",
    "#         assert abs(mu_action) < 2\n",
    "                                \n",
    "    # train minimise reward\n",
    "    for state, action, mu_action in zip(states, actions, mu_actions):\n",
    "        mu_action = abs(mu_action) if mu_action < -1 else mu_action\n",
    "        dlogpi = state * ((action - mu_action)/σ**2)\n",
    "        θ = θ + α * dlogpi * sum(rewards)\n",
    "    \n",
    "#     i = 0\n",
    "#     for state, action, mu_action in zip(states, actions, mu_actions):\n",
    "#         dlogpi = state * ((action - mu_action)/σ**2)\n",
    "#         R = 0\n",
    "#         for r in rewards[i:][::-1]:\n",
    "#             R = r + γ * R\n",
    "#         # minimise reward\n",
    "#         θ = θ + α * dlogpi * R\n",
    "\n",
    "#         i += 1\n",
    "        \n",
    "θ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actor-critic with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(observation_examples)\n",
    "\n",
    "# Used to converte a state to a featurizes represenation.\n",
    "# We use RBF kernels with different variances to cover different parts of the space\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "        (\"rbf1\", RBFSampler(gamma=5.0, n_components=100)),\n",
    "        (\"rbf2\", RBFSampler(gamma=2.0, n_components=100)),\n",
    "        (\"rbf3\", RBFSampler(gamma=1.0, n_components=100)),\n",
    "        (\"rbf4\", RBFSampler(gamma=0.5, n_components=100))\n",
    "        ])\n",
    "featurizer.fit(scaler.transform(observation_examples))\n",
    "\n",
    "def featurize_state(state):\n",
    "    \"\"\"\n",
    "    Returns the featurized representation for a state.\n",
    "    \"\"\"\n",
    "    scaled = scaler.transform([state])\n",
    "    featurized = featurizer.transform(scaled)\n",
    "    return featurized[0]\n",
    "\n",
    "state = env.observation_space.sample()\n",
    "featState = featurize_state(state)\n",
    "state, len(featState), featState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.backend import random_normal\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = Input(shape=400)\n",
    "μ = Dense(1, activation=None)(state)\n",
    "σ = Dense(1, activation=None)(state)\n",
    "# σ = tf.math.softplus(σ) + 1e-5\n",
    "\n",
    "action = random_normal(shape=(1, 1), mean=μ, stddev=σ)\n",
    "action = tf.clip_by_value(action, env.action_space.low[0], env.action_space.high[0])\n",
    "\n",
    "policyEstimator = Model(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.13246266, -0.12773119,  0.14095157, -0.08511366,  0.09100377,\n",
       "         -0.01563032,  0.01494   , -0.11525381,  0.12598155,  0.01621066,\n",
       "         -0.07662953, -0.04708563, -0.0379208 ,  0.05464486, -0.07814908,\n",
       "          0.14069131, -0.13721569, -0.10242794, -0.13826155,  0.1314298 ,\n",
       "          0.13952601, -0.03343887,  0.08508133, -0.08104398, -0.13889242,\n",
       "         -0.13320044,  0.1212669 ,  0.05445997,  0.10991691, -0.06585452,\n",
       "         -0.03454165, -0.03879303,  0.03079203, -0.00737028, -0.13605325,\n",
       "         -0.04802686, -0.13897802, -0.05802051, -0.09685986,  0.02399825,\n",
       "         -0.14137235, -0.1232097 , -0.13721324, -0.12164906,  0.13809611,\n",
       "          0.11326175, -0.01346296, -0.10940263, -0.01316769,  0.14140378,\n",
       "          0.09248487, -0.10120197, -0.06947694,  0.11920745, -0.14071681,\n",
       "          0.04742168,  0.14115267,  0.07627147,  0.05492381, -0.10158316,\n",
       "          0.07357183, -0.13508643, -0.04825777, -0.14098352,  0.01246688,\n",
       "          0.0263538 ,  0.13978305,  0.07110237,  0.12727977, -0.0630429 ,\n",
       "         -0.03848022, -0.01236841, -0.12556868,  0.07904826, -0.14142119,\n",
       "         -0.03925481, -0.10361784,  0.07791141, -0.13517234, -0.05677287,\n",
       "          0.04888329, -0.06098174, -0.03792476,  0.13970756, -0.0364945 ,\n",
       "          0.09396227, -0.14100975,  0.14011105,  0.06979073, -0.14134086,\n",
       "          0.14098318, -0.03256499,  0.01156094,  0.07263405, -0.10470132,\n",
       "         -0.13977851, -0.06542549, -0.08775911, -0.06612717, -0.13811331,\n",
       "          0.02160504, -0.1377905 ,  0.07578196, -0.12504912, -0.04755395,\n",
       "          0.0577669 ,  0.13448579,  0.14138749, -0.07871012, -0.10081909,\n",
       "         -0.10387939,  0.08802726, -0.12895849, -0.05535088, -0.13090285,\n",
       "         -0.05252024,  0.09065861,  0.09967027,  0.09115461, -0.10124904,\n",
       "         -0.1401695 ,  0.06193947,  0.00821315,  0.06157115, -0.05489604,\n",
       "         -0.08862299, -0.12613782,  0.13578988,  0.13652125, -0.12504129,\n",
       "         -0.14097048,  0.1326603 , -0.03421304,  0.13517612, -0.07542053,\n",
       "          0.03857381, -0.00444516,  0.06628759,  0.1341785 , -0.14140706,\n",
       "         -0.13372633, -0.13107398, -0.13731435,  0.0193659 , -0.14099776,\n",
       "         -0.1289245 ,  0.12927929, -0.11128517,  0.10733646, -0.09406795,\n",
       "          0.01777399,  0.00500145,  0.0850074 , -0.11337985,  0.07890688,\n",
       "          0.11731408, -0.06794023,  0.13048031,  0.1312712 ,  0.09847534,\n",
       "         -0.11784352,  0.13678711, -0.11607553, -0.13107455, -0.12537475,\n",
       "          0.12779437, -0.12973798, -0.04876334,  0.07192342,  0.14115486,\n",
       "         -0.06153765, -0.13978478, -0.12796752,  0.04003997, -0.05208081,\n",
       "          0.13295448, -0.12973474, -0.0163129 , -0.06782673, -0.11337319,\n",
       "         -0.10950499,  0.08178047,  0.00119179,  0.05794271,  0.09876674,\n",
       "         -0.13585649, -0.08602361, -0.1379155 ,  0.08524978, -0.14112906,\n",
       "          0.06435813, -0.04413724, -0.11359984, -0.11430494, -0.11588642,\n",
       "         -0.08093772,  0.09061572, -0.06468911, -0.09162546, -0.13791196,\n",
       "         -0.13976263,  0.13530899,  0.06152426, -0.00058357,  0.136189  ,\n",
       "          0.14135714, -0.08593444, -0.12279449,  0.14082241, -0.0944442 ,\n",
       "         -0.02116672, -0.11463587, -0.13852659, -0.12323597, -0.04951052,\n",
       "          0.08739313, -0.12349965,  0.0909928 , -0.13943894, -0.02201063,\n",
       "         -0.0236204 ,  0.13672015,  0.10122621,  0.05528706, -0.134669  ,\n",
       "          0.00992537, -0.07947715,  0.07902375, -0.13875732, -0.12180861,\n",
       "         -0.04910877, -0.13702343, -0.14072764, -0.02845184, -0.11760773,\n",
       "          0.13302198,  0.08644549, -0.13494657,  0.07303224, -0.12468891,\n",
       "          0.04245576,  0.07087492, -0.13718401,  0.09210947,  0.09105196,\n",
       "         -0.07238116,  0.07276108, -0.13761651, -0.09449792, -0.14081418,\n",
       "         -0.13869611,  0.04740188, -0.10635431,  0.12903872,  0.06818945,\n",
       "          0.04981758, -0.04877433,  0.08191541,  0.03836875,  0.03443529,\n",
       "          0.01644247,  0.14098898, -0.0870407 , -0.00444764,  0.01859058,\n",
       "          0.10389235,  0.08594145, -0.04892528,  0.07200396, -0.13459125,\n",
       "         -0.0810279 ,  0.13926012, -0.08696191, -0.1312314 , -0.09305452,\n",
       "         -0.00708389, -0.1322595 , -0.13446259, -0.13452577, -0.13707653,\n",
       "         -0.13192861, -0.11983469, -0.09714835, -0.08209968,  0.05494752,\n",
       "          0.01337824,  0.03086332, -0.05339451,  0.00625201,  0.02186509,\n",
       "          0.12717467,  0.12971119, -0.14136506,  0.0323194 ,  0.12450158,\n",
       "         -0.0517353 ,  0.13275716, -0.12091771,  0.01740598, -0.0902043 ,\n",
       "          0.13095716,  0.03184422,  0.07848214,  0.12859749, -0.13528509,\n",
       "          0.13045353, -0.00127491,  0.05580743, -0.1249861 , -0.13719338,\n",
       "          0.00776603,  0.14060046,  0.10451251,  0.09594468, -0.0610104 ,\n",
       "          0.04041252, -0.08815217,  0.11596572,  0.11425109,  0.13879466,\n",
       "          0.07380075,  0.02267703,  0.0094799 , -0.0547134 , -0.10628751,\n",
       "         -0.11001648,  0.08889804, -0.09972684, -0.04123089,  0.10999755,\n",
       "          0.12981432,  0.04201932, -0.08677656,  0.02254208,  0.10639234,\n",
       "         -0.1344747 , -0.13710307,  0.10263865, -0.12482723,  0.09888802,\n",
       "          0.03925942, -0.03327554, -0.00376572,  0.06207321, -0.13862847,\n",
       "          0.14086303, -0.09638759,  0.08533187,  0.13298392, -0.02779992,\n",
       "          0.10027679, -0.11669901,  0.07102412, -0.03387494,  0.0602393 ,\n",
       "          0.10773634, -0.12014609,  0.07363153,  0.11364908,  0.11348196,\n",
       "          0.05201827, -0.08559544, -0.13897749, -0.10741363, -0.03325039,\n",
       "          0.12098157, -0.08483461,  0.14103389,  0.02434517,  0.10625014,\n",
       "         -0.07452924,  0.0827555 ,  0.00125696, -0.10698749, -0.11839042,\n",
       "          0.14052527,  0.14141575, -0.14102827, -0.01748097, -0.12330623,\n",
       "          0.07284972,  0.11850444, -0.12954795,  0.08850506,  0.08550564,\n",
       "         -0.0930775 , -0.01834479, -0.06387734, -0.08701573,  0.10999475,\n",
       "          0.13750017,  0.03630236,  0.10023487,  0.0096861 , -0.06078733,\n",
       "         -0.13590129, -0.09539247, -0.09517788,  0.09438439, -0.10171106]]),\n",
       " array([[-0.07759663]], dtype=float32))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.observation_space.sample()\n",
    "s = featurize_state(s)\n",
    "s = np.array([s])\n",
    "s, policyEstimator.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyEstimator():\n",
    "    \"\"\" policy function approximator \"\"\"\n",
    "    def __init__(self, α=0.01, scope=\"policy_estimator\"):\n",
    "        with tf.variable_scope(scope):\n",
    "            self.state = tf.placeholder(tf.float32, [400], \"state\")\n",
    "            self.target = tf.placeholder(dtype=tf.float32, name=\"target\")\n",
    "\n",
    "            # This is just linear classifier\n",
    "            self.μ = tf.contrib.layers.fully_connected(\n",
    "                inputs=tf.expand_dims(self.state, 0),\n",
    "                num_outputs=1,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=tf.zeros_initializer)\n",
    "            self.μ = tf.squeeze(self.μ)\n",
    "            \n",
    "            self.σ = tf.contrib.layers.fully_connected(\n",
    "                inputs=tf.expand_dims(self.state, 0),\n",
    "                num_outputs=1,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=tf.zeros_initializer)\n",
    "            self.σ = tf.squeeze(self.σ)\n",
    "            self.σ = tf.nn.softplus(self.σ) + 1e-5\n",
    "\n",
    "            self.normal_dist = tf.contrib.distributions.Normal(self.μ, self.σ)\n",
    "            self.action = self.normal_dist._sample_n(1)\n",
    "            self.action = tf.clip_by_value(self.action, env.action_space.low[0], env.action_space.high[0])\n",
    "\n",
    "            # Loss and train op\n",
    "            self.loss = -self.normal_dist.log_prob(self.action) * self.target\n",
    "            # Add cross entropy cost to encourage exploration\n",
    "            self.loss -= 1e-1 * self.normal_dist.entropy()\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=α)\n",
    "            self.train_op = self.optimizer.minimize(\n",
    "                self.loss, global_step=tf.contrib.framework.get_global_step())\n",
    "            \n",
    "        def predict(self, state, sess=None):\n",
    "            sess = sess or tf.get_default_session()\n",
    "            state = featurize_state(state)\n",
    "            return sess.run(self.action, { self.state: state })\n",
    "        \n",
    "        def update(self, state, target, action, sess=None):\n",
    "            sess = sess or tf.get_default_session()\n",
    "            state = featurize_state(state)\n",
    "            feed_dict = { self.state: state, self.target: target, self.action: action  }\n",
    "            _, loss = sess.run([self.train_op, self.loss], feed_dict)\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueEstimator():\n",
    "    def __init__(self, α=0.1, scope=\"value_estimator\"):\n",
    "        with tf.variable_scope(scope):\n",
    "            self.state = tf.placeholder(tf.float32, [400], \"state\")\n",
    "            \n",
    "            self.target = tf.placeholder(dtype=tf.float32, name=\"target\")\n",
    "            # This is just linear classifier\n",
    "            self.output_layer = tf.contrib.layers.fully_connected(\n",
    "                inputs=tf.expand_dims(self.state, 0),\n",
    "                num_outputs=1,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=tf.zeros_initializer)\n",
    "\n",
    "            self.value_estimate = tf.squeeze(self.output_layer)\n",
    "            self.loss = tf.squared_difference(self.value_estimate, self.target)\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=α)\n",
    "            self.train_op = self.optimizer.minimize(\n",
    "                self.loss, global_step=tf.contrib.framework.get_global_step())        \n",
    "    \n",
    "    def predict(self, state, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        state = featurize_state(state)\n",
    "        return sess.run(self.value_estimate, { self.state: state })\n",
    "\n",
    "    def update(self, state, target, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        state = featurize_state(state)\n",
    "        feed_dict = { self.state: state, self.target: target }\n",
    "        _, loss = sess.run([self.train_op, self.loss], feed_dict)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core.compat.v1' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-ddfa96dd3cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicy_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolicyEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mα\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalue_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValueEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mα\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-77918c141132>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, α, scope)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# This is just linear classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             self.μ = tf.contrib.layers.fully_connected(\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core.compat.v1' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "policy_estimator = PolicyEstimator(α=0.001)\n",
    "value_estimator = ValueEstimator(α=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
