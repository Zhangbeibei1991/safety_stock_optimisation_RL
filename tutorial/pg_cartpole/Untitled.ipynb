{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eek31/Documents/openai/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951da9236b44aee8540f4644a54a015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748d5b95caf14e67a1fa2153e3aa5d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a45b8b3d8c445d18096736e3f2de440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956a8c9c044644a6a898ee68e835e64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c523fd5fd54e95aaffe170149b3035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e43e6a318654b0c9c1b05378b98cba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c220b09cad264568af8335106e0b7ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930692407dfb4c609a18795dc74bded1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa50084c4b6d483aa5414c990a74c3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a68703e1634e79802d2849efc5d717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10aa366a26ad46aa952d9fa42130d45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285e22f3398b4d34bc2efb5d496fee33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8503722df4494aa8f4df81fc030c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8827afe0642f4ecd80440a4935d7516c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30de067346e4805912e2ac14a33e066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8afc96dced4568a6160187661d3cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe4ecddf5da4cd6a2a2d4fa4409541f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b01f7be94e485a8b58058ce498d8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d08507cc1c4bdbad8bfb0cb1982554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41396df3e5eb47e2adc8638087331a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924babbf2f2f4605a9952bbbe2f07461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "# preprocessing\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "# Feature Preprocessing: Normalize to zero mean and unit variance\n",
    "# We use a few samples from the observation space to do this\n",
    "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(observation_examples)\n",
    "# Used to convert a state to a featurizes represenation.\n",
    "# We use RBF kernels with different variances to cover different parts of the space\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "        (\"rbf1\", RBFSampler(gamma=5.0, n_components=100)),\n",
    "        (\"rbf2\", RBFSampler(gamma=2.0, n_components=100)),\n",
    "        (\"rbf3\", RBFSampler(gamma=1.0, n_components=100)),\n",
    "        (\"rbf4\", RBFSampler(gamma=0.5, n_components=100))\n",
    "        ])\n",
    "featurizer.fit(scaler.transform(observation_examples))\n",
    "def featurize_state(state):\n",
    "    \"\"\"\n",
    "    Returns the featurized representation for a state.\n",
    "    \"\"\"\n",
    "    scaled = scaler.transform([state])\n",
    "    featurized = featurizer.transform(scaled)\n",
    "    return featurized[0]\n",
    "\n",
    "\n",
    "class PolicyEstimator():\n",
    "    def __init__(self, α = 0.01):\n",
    "        self.θ = np.zeros(400, )\n",
    "        self.σ = 1\n",
    "        self.α = α\n",
    "        \n",
    "        self.v_dθ = np.zeros(400,)\n",
    "        self.β = 0.9\n",
    "        self.ε = 1e-10\n",
    "        \n",
    "    def mu_state(self, state):\n",
    "        mu = self.θ @ state\n",
    "        \n",
    "        return mu\n",
    "          \n",
    "    def predict(self, state):\n",
    "        mu = self.mu_state(state)\n",
    "        \n",
    "        action = np.random.normal(mu, self.σ, size=(1,))\n",
    "        action = np.clip(action, env.action_space.low[0], env.action_space.high[0])\n",
    "        return action\n",
    "    \n",
    "    def update(self, state, target, action):\n",
    "        mu = self.mu_state(state)\n",
    "        \n",
    "        # update θ\n",
    "        dloss = -((action - mu)/(self.σ**2)) * state * target\n",
    "        # rmsprop optimisation\n",
    "        self.v_dθ = self.β * self.v_dθ + (1 - self.β) * (dloss**2) \n",
    "        self.θ -= self.α * dloss/(np.sqrt(self.v_dθ) + self.ε)\n",
    "        \n",
    "class ValueEstimator():\n",
    "    def __init__(self, α = 0.1):\n",
    "        self.w = np.zeros(400, )\n",
    "        self.α = α\n",
    "        \n",
    "        self.v_dw = np.zeros(400,)\n",
    "        self.β = 0.9\n",
    "        self.ε = 1e-10\n",
    "               \n",
    "    def predict(self, state):\n",
    "        value = self.w @ state\n",
    "        return value\n",
    "    \n",
    "    def update(self, state, target):\n",
    "        value = self.predict(state)\n",
    "               \n",
    "        # update w\n",
    "        dloss = 2*(value - target)*state\n",
    "        # rmsprop optimisation\n",
    "        self.v_dw = self.β * self.v_dw + (1 - self.β) * (dloss**2) \n",
    "        self.w -= self.α * dloss/(np.sqrt(self.v_dw) + self.ε)\n",
    "        \n",
    "policy_estimator = PolicyEstimator(α=0.001)\n",
    "value_estimator = ValueEstimator(α=0.1)\n",
    "\n",
    "\"\"\"\n",
    "TRAIN\n",
    "\"\"\"\n",
    "num_episodes = 20\n",
    "num_steps = 1000\n",
    "discount_factor=0.95\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    # set v_dw and v_dθ to 0\n",
    "    state = env.reset()\n",
    "    state = featurize_state(state)\n",
    "    for t in tqdm_notebook(range(num_steps)):\n",
    "        # take action\n",
    "        action = policy_estimator.predict(state)\n",
    "        # execute action\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = featurize_state(next_state)\n",
    "        # calculate TD target\n",
    "        value_now = value_estimator.predict(state)\n",
    "        value_next = value_estimator.predict(next_state)\n",
    "        td_target = reward + discount_factor * value_next\n",
    "        td_error = td_target - value_now\n",
    "        # update the value estimator\n",
    "        value_estimator.update(state, td_target)\n",
    "        # update the policy estimator\n",
    "        policy_estimator.update(state, td_error, action)\n",
    "        if done & (t <= 900):\n",
    "            break\n",
    "        state = next_state\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "TEST\n",
    "\"\"\"\n",
    "num_steps = 1000\n",
    "# remove random exploration from policy\n",
    "policy_estimator.σ = 0\n",
    "state = env.reset()\n",
    "state = featurize_state(state)\n",
    "for t in tqdm_notebook(range(num_steps)):\n",
    "    env.render()\n",
    "    time.sleep(0.01)    \n",
    "    \n",
    "    # take action\n",
    "    action = policy_estimator.predict(state)\n",
    "    # execute action\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    next_state = featurize_state(next_state)\n",
    "    if done:\n",
    "        break\n",
    "    state = next_state\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
